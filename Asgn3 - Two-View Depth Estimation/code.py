# -*- coding: utf-8 -*-
"""project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fk5laEUbba6cm5DGBtTevpewraWsoro7
"""

import numpy as np
import cv2
import argparse
import math
from tqdm import tqdm
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

img1 = cv2.imread('/content/drive/MyDrive/cv project/data/curule/im0.png')
img2 = cv2.imread('/content/drive/MyDrive/cv project/data/curule/im1.png')

img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

sift = cv2.SIFT_create()
keyp1, descriptors1 = sift.detectAndCompute(img1, None)
keyp2, descriptors2 = sift.detectAndCompute(img2, None)


keypointimage1 = cv2.drawKeypoints(img1, keyp1, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
cv2_imshow( keypointimage1)
cv2.waitKey()

keypointimage2 = cv2.drawKeypoints(img2, keyp2, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
cv2_imshow(keypointimage2)
cv2.waitKey()

bf_matcher = cv2.BFMatcher()
matches = bf_matcher.match(descriptors1, descriptors2)

# Sort the matches based on distance
matches = sorted(matches, key=lambda x: x.distance)

# Draw the top 'n' matches (e.g., 10 matches)
n = 50
matches=matches[:n]
matching_result = cv2.drawMatches(img1, keyp1, img2, keyp2, matches[:n], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

# Display the matching result
cv2_imshow(matching_result)
cv2.waitKey()

# Extract matched points
points1 = np.float32([keyp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
points2 = np.float32([keyp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)

# Calculate the fundamental matrix using RANSAC
fundamental_matrix, mask = cv2.findFundamentalMat(points1, points2, cv2.FM_RANSAC)

# Filter out non-inlier points
points1_inliers = points1[mask.ravel() == 1]
points2_inliers = points2[mask.ravel() == 1]

print("Fundamental Matrix:")
print(fundamental_matrix)

#intrinsic parameters of two cameras taken form calib.txt file in dataset
k1= [[1758.23,0,977.42],[0, 1758.23, 552.15],[0, 0, 1]]
k2=[[1758.23, 0 ,977.42],[0, 1758.23, 552.15],[0 ,0 ,1]]

#compute essential matrix
essential_matrix = np.matmul(np.array(k2).transpose(),(np.matmul(np.array(fundamental_matrix),np.array(k1))))

print("Essential Matrix:")
print(essential_matrix)

def Restore_cam_pose(E):
  '''
  Conceptual basis from : https://cmsc733.github.io/2022/proj/p3/#estfundmatrix
  '''
  U, S, V_T = np.linalg.svd(E)
  W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])

  Rot = []
  trans = []

  ###--- 4 Rotational configurations ---###
  Rot.append(np.dot(U, np.dot(W, V_T)))
  Rot.append(np.dot(U, np.dot(W, V_T)))
  Rot.append(np.dot(U, np.dot(W.T, V_T)))
  Rot.append(np.dot(U, np.dot(W.T, V_T)))

  ###-- 4 translational configurations ---###
  trans.append(U[:, 2])
  trans.append(-U[:, 2])
  trans.append(U[:, 2])
  trans.append(-U[:, 2])

  ###--- Retrieving the best cam pose config ---###
  for i in range(4):
      if (np.linalg.det(Rot[i]) < 0):
          Rot[i] = -Rot[i]
          trans[i] = -trans[i]

  return Rot, trans

def check_cheirality(pts_3D,trans,Rot):
  best_pts = 0
  for P in pts_3D:
      P = P.reshape(-1,1)
      if Rot.dot(P - trans) > 0 and P[2]>0:
          best_pts+=1
  return best_pts

R2_, C2_ = Restore_cam_pose(essential_matrix)
Pts_3D = []
R1  = np.identity(3)
C1  = np.zeros((3, 1))
I = np.identity(3)

####---- Triangulation----####
for i in range(len(R2_)):
  R2 =  R2_[i]
  C2 =   C2_[i].reshape(3,1)
  Proj_mat_im0 = np.dot(k1, np.dot(R1, np.hstack((I, -C1.reshape(3,1)))))
  Proj_mat_im1 = np.dot(k2, np.dot(R2, np.hstack((I, -C2.reshape(3,1)))))

  for x_left_img,x_right_img in zip(points1_inliers[:,0:2], points2_inliers[:,0:2]):
    pts_3d = cv2.triangulatePoints(Proj_mat_im0, Proj_mat_im1, np.float32(x_left_img[0]), np.float32(x_right_img[0]))
    pts_3d = np.array(pts_3d)
    pts_3d = pts_3d[0:3,0]
    Pts_3D.append(pts_3d)

best_indices = 0
max_Positive = 0

### --Camera Pose Restoration--###
for i in range(len(R2_)):
  R_, C_ = R2_[i],  C2_[i].reshape(-1,1)
  R_3 = R_[2].reshape(1,-1)
  num_Positive = check_cheirality(Pts_3D,C_,R_3)

  if num_Positive > max_Positive:
      best_indices = i
      max_Positive = num_Positive

Rotation_coniguration, Translation_coniguration, P3D = R2_[best_indices], C2_[best_indices], Pts_3D[best_indices]

print(" Camera Pose: (Rotation) \n",Rotation_coniguration,'\n')
print(" Camera Pose: (Translation) \n", Translation_coniguration, '\n')

###################################################################
##----------------- RECTIFICATION--------------------------------##
###################################################################

pts_set1,pts_set2= points1_inliers[:,0:2], points2_inliers[:,0:2]

lines1, lines2 = Compute_epi_lines(pts_set1, pts_set2, F_best, image0, image1, "results/epi_polar_lines_" + str(dataset_number)+ ".png", False)

h1, w1 = image0.shape[:2]
h2, w2 = image1.shape[:2]
_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(pts_set1), np.float32(pts_set2), F_best, imgSize=(w1, h1))
print("Estimated H1 and H2 as \n \n Homography Matrix 1: \n", H1,'\n \n Homography Matrix 2:\n ', H2)

img1_rectified = cv2.warpPerspective(image0, H1, (w1, h1))
img2_rectified = cv2.warpPerspective(image1, H2, (w2, h2))


pts_set1_rectified = cv2.perspectiveTransform(pts_set1.reshape(-1, 1, 2), H1).reshape(-1,2)
pts_set2_rectified = cv2.perspectiveTransform(pts_set2.reshape(-1, 1, 2), H2).reshape(-1,2)

H2_T_inv =  np.linalg.inv(H2.T)
H1_inv = np.linalg.inv(H1)
F_rectified = np.dot(H2_T_inv, np.dot(F_best, H1_inv))

lines1_rectified, lines2_rectified = Compute_epi_lines(pts_set1_rectified, pts_set2_rectified, F_rectified, img1_rectified, img2_rectified, "results/rectified_epi_polar_lines_" + str(dataset_number)+ ".png",  True)

img1_rectified_reshaped = cv2.resize(img1_rectified, (int(img1_rectified.shape[1] / 4), int(img1_rectified.shape[0] / 4)))
img2_rectified_reshaped = cv2.resize(img2_rectified, (int(img2_rectified.shape[1] / 4), int(img2_rectified.shape[0] / 4)))

img1_rectified_reshaped = cv2.cvtColor(img1_rectified_reshaped, cv2.COLOR_BGR2GRAY)
img2_rectified_reshaped = cv2.cvtColor(img2_rectified_reshaped, cv2.COLOR_BGR2GRAY)